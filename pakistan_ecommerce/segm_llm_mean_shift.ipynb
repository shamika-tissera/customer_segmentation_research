{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import skfuzzy as fuzz\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, accuracy_score, classification_report\n",
    "from pyod.models.ecod import ECOD\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "import prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df = pd.read_csv('../datasets/Pakistan_Ecommerce/rfm.csv')\n",
    "embedding_df = pd.read_csv('../datasets/Pakistan_Ecommerce/rfm_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca_2d(df, predict):\n",
    "    pca_2d_object = prince.PCA(\n",
    "    n_components=2,\n",
    "    n_iter=3,\n",
    "    rescale_with_mean=True,\n",
    "    rescale_with_std=True,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    pca_2d_object.fit(df)\n",
    "\n",
    "    df_pca_2d = pca_2d_object.transform(df)\n",
    "    df_pca_2d.columns = [\"comp1\", \"comp2\"]\n",
    "    df_pca_2d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_2d_object, df_pca_2d\n",
    "\n",
    "\n",
    "\n",
    "def get_pca_3d(df, predict):\n",
    "    pca_3d_object = prince.PCA(\n",
    "        n_components=3,\n",
    "        n_iter=3,\n",
    "        rescale_with_mean=True,\n",
    "        rescale_with_std=True,\n",
    "        copy=True,\n",
    "        check_input=True,\n",
    "        engine='sklearn',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    pca_3d_object.fit(df)\n",
    "\n",
    "    df_pca_3d = pca_3d_object.transform(df)\n",
    "    df_pca_3d.columns = [\"comp1\", \"comp2\", \"comp3\"]\n",
    "    df_pca_3d[\"cluster\"] = predict\n",
    "\n",
    "    return pca_3d_object, df_pca_3d\n",
    "\n",
    "\n",
    "\n",
    "def plot_pca_3d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter_3d(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        z='comp3',\n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        \n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 4,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 1000, \n",
    "                                height = 800, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            zaxis=dict(title = 'comp3', titlefont_color = 'black')),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                      \n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def plot_pca_2d(df, title = \"PCA Space\", opacity=0.8, width_line = 0.1):\n",
    "\n",
    "    df = df.astype({\"cluster\": \"object\"})\n",
    "    df = df.sort_values(\"cluster\")\n",
    "\n",
    "    fig = px.scatter(df, \n",
    "                        x='comp1', \n",
    "                        y='comp2', \n",
    "                        color='cluster',\n",
    "                        template=\"plotly\",\n",
    "                        # symbol = \"cluster\",\n",
    "                        \n",
    "                        color_discrete_sequence=px.colors.qualitative.Vivid,\n",
    "                        title=title).update_traces(\n",
    "                            # mode = 'markers',\n",
    "                            marker={\n",
    "                                \"size\": 8,\n",
    "                                \"opacity\": opacity,\n",
    "                                # \"symbol\" : \"diamond\",\n",
    "                                \"line\": {\n",
    "                                    \"width\": width_line,\n",
    "                                    \"color\": \"black\",\n",
    "                                }\n",
    "                            }\n",
    "                        ).update_layout(\n",
    "                                width = 800, \n",
    "                                height = 700, \n",
    "                                autosize = False, \n",
    "                                showlegend = True,\n",
    "                                legend=dict(title_font_family=\"Times New Roman\",\n",
    "                                            font=dict(size= 20)),\n",
    "                                scene = dict(xaxis=dict(title = 'comp1', titlefont_color = 'black'),\n",
    "                                            yaxis=dict(title = 'comp2', titlefont_color = 'black'),\n",
    "                                            ),\n",
    "                                font = dict(family = \"Gilroy\", color  = 'black', size = 15))\n",
    "                        \n",
    "        \n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.ecod import ECOD\n",
    "# https://github.com/yzhao062/pyod\n",
    "\n",
    "# Unsupervised Outlier Detection Using Empirical Cumulative Distribution Functions (ECOD)\n",
    "clf = ECOD()\n",
    "clf.fit(embedding_df.iloc[:, 1:])\n",
    "\n",
    "out = clf.predict(embedding_df.iloc[:, 1:]) \n",
    "embedding_df[\"outliers\"] = out\n",
    "rfm_df[\"outliers\"] = out\n",
    "\n",
    "df_embedding_no_out = embedding_df[embedding_df[\"outliers\"] == 0]\n",
    "df_embedding_no_out = df_embedding_no_out.drop([\"outliers\"], axis = 1)\n",
    "rfm_df_no_out = rfm_df[rfm_df[\"outliers\"] == 0]\n",
    "rfm_df_no_out = rfm_df_no_out.drop([\"outliers\"], axis = 1)\n",
    "\n",
    "df_embedding_with_out = embedding_df.copy()\n",
    "df_embedding_with_out = df_embedding_with_out.drop([\"outliers\"], axis = 1)\n",
    "rfm_df_with_out = rfm_df.copy()\n",
    "rfm_df_with_out = rfm_df_with_out.drop([\"outliers\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 131. MiB for an array with shape (22338, 769) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mg:\\GitHub\\customer_segmentation_research\\pakistan_ecommerce\\segm_llm_mean_shift.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitHub/customer_segmentation_research/pakistan_ecommerce/segm_llm_mean_shift.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m MeanShift\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitHub/customer_segmentation_research/pakistan_ecommerce/segm_llm_mean_shift.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ms \u001b[39m=\u001b[39m MeanShift()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/GitHub/customer_segmentation_research/pakistan_ecommerce/segm_llm_mean_shift.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ms\u001b[39m.\u001b[39;49mfit(df_embedding_no_out)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitHub/customer_segmentation_research/pakistan_ecommerce/segm_llm_mean_shift.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m predict \u001b[39m=\u001b[39m ms\u001b[39m.\u001b[39mpredict(df_embedding_no_out)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/GitHub/customer_segmentation_research/pakistan_ecommerce/segm_llm_mean_shift.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m df_embedding_no_out[\u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m predict\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\cluster\\_mean_shift.py:480\u001b[0m, in \u001b[0;36mMeanShift.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    477\u001b[0m nbrs \u001b[39m=\u001b[39m NearestNeighbors(radius\u001b[39m=\u001b[39mbandwidth, n_jobs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m    479\u001b[0m \u001b[39m# execute iterations on all seeds in parallel\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m all_res \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    481\u001b[0m     delayed(_mean_shift_single_seed)(seed, X, nbrs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter)\n\u001b[0;32m    482\u001b[0m     \u001b[39mfor\u001b[39;49;00m seed \u001b[39min\u001b[39;49;00m seeds\n\u001b[0;32m    483\u001b[0m )\n\u001b[0;32m    484\u001b[0m \u001b[39m# copy results in a dictionary\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(seeds)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\cluster\\_mean_shift.py:109\u001b[0m, in \u001b[0;36m_mean_shift_single_seed\u001b[1;34m(my_mean, X, nbrs, max_iter)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[39m# Find mean of points within bandwidth\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     i_nbrs \u001b[39m=\u001b[39m nbrs\u001b[39m.\u001b[39mradius_neighbors([my_mean], bandwidth, return_distance\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 109\u001b[0m     points_within \u001b[39m=\u001b[39m X[i_nbrs]\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(points_within) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    111\u001b[0m         \u001b[39mbreak\u001b[39;00m  \u001b[39m# Depending on seeding strategy this condition may occur\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 131. MiB for an array with shape (22338, 769) and data type float64"
     ]
    }
   ],
   "source": [
    "# Mean Shift\n",
    "from sklearn.cluster import MeanShift\n",
    "ms = MeanShift()\n",
    "ms.fit(df_embedding_no_out)\n",
    "predict = ms.predict(df_embedding_no_out)\n",
    "df_embedding_no_out[\"cluster\"] = predict\n",
    "df_embedding_no_out[\"cluster\"] = df_embedding_no_out[\"cluster\"].astype(\"object\")\n",
    "\n",
    "df_embedding_no_out[\"cluster\"].value_counts()\n",
    "\n",
    "# PCA 3D\n",
    "pca_3d_object, df_pca_3d = get_pca_3d(df_embedding_no_out, predict)\n",
    "plot_pca_3d(df_pca_3d, title = \"Mean Shift Clustering\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
